{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e8029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import calplot\n",
    "import calmap\n",
    "import csv\n",
    "import sklearn\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,StratifiedKFold,cross_val_score,learning_curve\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "from nltk.corpus import words \n",
    "from IPython.display import HTML, display\n",
    "import email_read_util\n",
    "from datasketch import MinHash, MinHashLSH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cab7c2b",
   "metadata": {},
   "source": [
    "<h2>Overview of the data and data source.</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b7ffd",
   "metadata": {},
   "source": [
    "This dataset contains and excert of Spam and Ham E-Mails from the Enron Corpus. \n",
    "\n",
    "Enron was an american company, that due to financial fraud collapse and subsequentiall was under investigation by law enforcement agencies. During these investigations, E-Mails servers were seized and later published. \n",
    "\n",
    "Today this corpus is special, as it is only one of the few datsets, that actually contain 'real' E-Mails ready for analysis. \n",
    "\n",
    "The entire Corpus is around 600000 E-Mails, for this project a smaller subset is being used for Spam detection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84497d2",
   "metadata": {},
   "source": [
    "<h2>Goals of the project</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bc955",
   "metadata": {},
   "source": [
    "The goal of the project is to analyze different Spam. Several goals: \n",
    "\n",
    "1. Find the best Spam filter\n",
    "2. Determine which effect on the Spam recognition the Subject line has. \n",
    "3. Determine the best Dataset for Spam detection out of a number of datasets --> e.g. train with 5 datasets and test on 6 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdb71e",
   "metadata": {},
   "source": [
    "<h2>Preprocessing and Cleaning</h2<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './enron_spam_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863494f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = enron_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e30062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671187a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed6f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04aef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_label = enron_df['Spam/Ham'].value_counts()\n",
    "print(enron_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf8245d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df['Spam/Ham'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491df6bf",
   "metadata": {},
   "source": [
    "Noticing the NaN in the first message shown above, I decided to anayze how complete the dataset is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3693702",
   "metadata": {},
   "outputs": [],
   "source": [
    "messageID_NaN = enron_df['Message ID'].isna().sum()\n",
    "subject_NaN = enron_df['Subject'].isna().sum()\n",
    "message_NaN = enron_df['Message'].isna().sum()\n",
    "spam_NaN = enron_df['Spam/Ham'].isna().sum()\n",
    "print(f\"Number of NaN values in 'Message ID' column: {messageID_NaN}\")\n",
    "print(f\"Number of NaN values in 'Subject' column: {subject_NaN}\")\n",
    "print(f\"Number of NaN values in 'Message' column: {message_NaN}\")\n",
    "print(f\"Number of NaN values in 'Spam/Ham' column: {spam_NaN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2148ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_nan = subject_NaN + message_NaN\n",
    "percentage_nan = max_nan / len(enron_df)\n",
    "print('Total Maximum Lost E-Mails:' ,max_nan)\n",
    "print('Percentage of Total E-Mails:',percentage_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ebf66f",
   "metadata": {},
   "source": [
    "As we can see, a maximum of 660 E-Mails would be lost if we dropped all NaN values. While this is only 1,9% of all E-Mails, we risk eleminating Spam messages and tainting the analysis. Therefore I analyze how many of the 'subjectless' E-Mails are Spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af09fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_and_spam_sub = len(enron_df[(enron_df[\"Subject\"].isna()) & (enron_df[\"Spam/Ham\"]=='spam')])\n",
    "na_and_spam_mes = len(enron_df[(enron_df[\"Message\"].isna()) & (enron_df[\"Spam/Ham\"]=='spam')])\n",
    "print('Subject = NaN && is Spam:',na_and_spam_sub)\n",
    "print('Message = NaN && is spam:' ,na_and_spam_mes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5d9af",
   "metadata": {},
   "source": [
    "Interestingly enough, all of the message where there is no subject are classified as Spam.\n",
    "For Messages with no Body, this happens also for most of the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5091b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enron_df[enron_df['Subject'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2642902",
   "metadata": {},
   "source": [
    "Taking a quick peek at these couple of message, they indeed appear to be Spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729cb9d3",
   "metadata": {},
   "source": [
    "Let us now count the number of message where there is no subject line and no body: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_message = len(enron_df[(enron_df[\"Subject\"].isna()) & (enron_df[\"Message\"].isna())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(empty_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c35122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enron_df[(enron_df[\"Subject\"].isna()) & (enron_df[\"Message\"].isna())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe89e50d",
   "metadata": {},
   "source": [
    "Indeed there are 51 message that do not contain Subject and Message. We will leave those in the dataframe, as they are nevertheless Spam. While they are probably not Harmful (maybe except for DoS against the server), they can be annoying for the enduse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444f3a10",
   "metadata": {},
   "source": [
    "As can be seen above, we notice the Column Date. While it is surely interesting to correlate the impending doom of financial collapse of the company to the amount of E-Mails send in that time frame, having the date for detecting Spams is not necessary. \n",
    "\n",
    "Potentially for later graphics it would be interesting to see, if Spam is sent on the weekend or not.\n",
    "\n",
    "In any case, for now we can safely ignore the Date column: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a129dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.drop('Date', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba79e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = enron_df[enron_df['Message'].duplicated() == True].sort_values('Message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e99bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed90ab3d",
   "metadata": {},
   "source": [
    "Obviously if we consider the nature of Spam messages, it becomes clear that some of the received messages are Duplicates. I have decided to remove all of these duplicates, as we do not want to have any bias in the following analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade75121",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b40780",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.drop_duplicates(subset=['Message'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808caa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cf65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = len(enron_df[enron_df['Subject'].duplicated() == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ada071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d0cbc",
   "metadata": {},
   "source": [
    "As we can see, there are also 6205 dubplicated subjects. This surprised me, as it represent a significant part of all the messages. NEverthless I decided to not remove those messages, as we have already remove messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45692ff",
   "metadata": {},
   "source": [
    "As Python is casesensitive I have decided to transform all words into lowercase. ALthough it appears the dataset is already completly in lowercase, I do this for safety reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11bc7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df['Message'] = enron_df['Message'].str.lower()\n",
    "enron_df['Subject'] = enron_df['Subject'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc379c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df[\"Message\"] = enron_df['Message'].str.replace('[^\\w\\s]','', regex=True)\n",
    "enron_df[\"Subject\"] = enron_df['Subject'].str.replace('[^\\w\\s]','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbd113",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddddede",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "enron_df['Message'] = enron_df['Message'].fillna('')\n",
    "enron_df['Subject'] = enron_df['Subject'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df['Message'] = enron_df['Message'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "enron_df['Subject'] = enron_df['Subject'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a8ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6399d0a3",
   "metadata": {},
   "source": [
    "As we can see removing punctuation and stopwords works fine. Sadly as we can see, due to reasons the NaN values had to be replaced with NaN. #################Potentially fix this alter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a796db8a",
   "metadata": {},
   "source": [
    "In the next step we divide the dataset into training data and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c62e9d",
   "metadata": {},
   "source": [
    "Having thought about how to handle the subject line of the message, I decideded to view the subject line simply as a \"Headline\", and therefore decided to unfiy message and subject into one column. In a sense, this also solves our NaN problem, as it is now ensure that every anaylze E-Mail has a unified message we can look at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e91f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df['unified'] = enron_df['Subject'] + ' ' + enron_df['Message']\n",
    "enron_df_unified = enron_df.drop(['Subject', 'Message'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc8a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df_unified.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35115a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_rows = enron_df_unified[enron_df_unified['Spam/Ham'].isna() | (enron_df_unified['Spam/Ham'] == ' ')]\n",
    "print(na_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f9479",
   "metadata": {},
   "source": [
    "As a last step, I decide to randomlay arrange the order of rows, so there is no bias: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987f7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_df_unified = enron_df_unified.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbff27c",
   "metadata": {},
   "source": [
    "At this point, our dataframe is ready to be analyzed. We can begin with the training using the enron_df_uniied df. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f88b6b",
   "metadata": {},
   "source": [
    "<h2>Naive Bayes Filter</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471bc2a",
   "metadata": {},
   "source": [
    "We will start with the Naive Bayes Filter. In this stage we start to analyze firstly our unified version of the subject and the E-Mail body. \n",
    "\n",
    "Later we take a look how well this Bayes Filter works, when we analyze the Subject Line and the E-Mail body separatly.\n",
    "\n",
    "Lastly I use a different way to implement the Bayes Filter that I found online: the description can be found here: https://www.kdnuggets.com/2020/07/spam-filter-python-naive-bayes-scratch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd049978",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efce3cd",
   "metadata": {},
   "source": [
    "<h3>Unified Subject Line and E-Mail Body</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unified = enron_df_unified['unified']\n",
    "y_unified = enron_df_unified['Spam/Ham']\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = \\\n",
    "    train_test_split(X_unified, y_unified, range(len(y_unified)), \n",
    "    train_size=training_ratio, random_state=1)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vector = vectorizer.fit_transform(X_train)\n",
    "X_test_vector = vectorizer.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vector, y_train)\n",
    "y_pred = mnb.predict(X_test_vector)\n",
    "\n",
    "results_df = pd.concat([y_test.reset_index(drop=True), pd.Series(y_pred)], axis=1, keys=['true', 'predicted'])\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['Spam', 'Ham']))\n",
    "print('Classification accuracy {:.1%}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa3ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = 0\n",
    "for i, row in results_df.iterrows():\n",
    "    if row['true'] != row['predicted']:\n",
    "        print(f\"Predicted: {row['predicted']}, True: {row['true']},\\nText: {X_test.iloc[i]}\\n\")\n",
    "        wrong_predictions += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ed279",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of wrong predictions: {wrong_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f91df4c",
   "metadata": {},
   "source": [
    "<h1>#########NOTE: NEED TO ANALYZE THIS NOW</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0ee5a",
   "metadata": {},
   "source": [
    "<h3>Analyzing only the subject line</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e626b8e",
   "metadata": {},
   "source": [
    "Let us now try to analyze what happens if we only observe the Subject headers. How does this affect the Spam detection accuracy?\n",
    "\n",
    "My suspicion is, that this will lower the recognition rate of Spam significantly. I even suspect it will make the Spam Filter completly worthless, with possible prediction rates approach 60% or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2aef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_NaN = enron_df['Subject'].isna().sum()\n",
    "subject_empty = (enron_df['Subject'] == ' ').sum()\n",
    "\n",
    "print(subject_NaN)\n",
    "print(subject_empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d023a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subject = enron_df['Subject']\n",
    "y_subject = enron_df['Spam/Ham']\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = \\\n",
    "    train_test_split(X_subject, y_subject, range(len(y_unified)), \n",
    "    train_size=training_ratio, random_state=1)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vector = vectorizer.fit_transform(X_train)\n",
    "X_test_vector = vectorizer.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vector, y_train)\n",
    "y_pred = mnb.predict(X_test_vector)\n",
    "\n",
    "results_df = pd.concat([y_test.reset_index(drop=True), pd.Series(y_pred)], axis=1, keys=['true', 'predicted'])\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['Spam', 'Ham']))\n",
    "print('Classification accuracy {:.1%}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4507b1",
   "metadata": {},
   "source": [
    "As we can see, even when only anayzing the subject line it can still reach a correct predicition of 90.3%, which is not great but still much better than expected. Still quite useless though and it confirms the suspicion that only using the Subject Line to analyze Spam is definitly not enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7be839",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = 0\n",
    "for i, row in results_df.iterrows():\n",
    "    if row['true'] != row['predicted']:\n",
    "        print(f\"Predicted: {row['predicted']}, True: {row['true']},\\nText: {X_test.iloc[i]}\\n\")\n",
    "        wrong_predictions += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cb28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of wrong predictions: {wrong_predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c85118",
   "metadata": {},
   "source": [
    "<h3>Analyzing only the E-Mail Body</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e164b93",
   "metadata": {},
   "source": [
    "Now lets try the same with only the message body and see how much effect the Subject has on the Spam detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6277f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_body = enron_df['Message']\n",
    "y_body = enron_df['Spam/Ham']\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = \\\n",
    "    train_test_split(X_body, y_body, range(len(y_unified)), \n",
    "    train_size=training_ratio, random_state=1)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vector = vectorizer.fit_transform(X_train)\n",
    "X_test_vector = vectorizer.transform(X_test)\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_vector, y_train)\n",
    "y_pred = mnb.predict(X_test_vector)\n",
    "\n",
    "results_df = pd.concat([y_test.reset_index(drop=True), pd.Series(y_pred)], axis=1, keys=['true', 'predicted'])\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=['Spam', 'Ham']))\n",
    "print('Classification accuracy {:.1%}'.format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcf8125",
   "metadata": {},
   "source": [
    "It has 98.4%! This is quite good. But still less than the unification of the body and the Subject. Therefore it makes sense to use the first method which unfies both Subject Line and E-Mail body. \n",
    "\n",
    "For future analysis and representation, only the first analysis type will be considered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a01091",
   "metadata": {},
   "source": [
    "<h2>############### TO DO Blacklisting --> Need to randomize order of files</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bl = enron_df_unified[:int(len(enron_df_unified)*training_ratio)]\n",
    "X_test_bl = enron_df_unified[int(len(enron_df_unified)*training_ratio):]\n",
    "x_train_Spam_bl = enron_df_unified['Spam/Ham']\n",
    "stemmer = nltk.PorterStemmer()\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "spam_words = set()\n",
    "ham_words = set()\n",
    "\n",
    "\n",
    "for _, row in X_train_bl.iterrows():\n",
    "    path = row['unified']\n",
    "    label = row['Spam/Ham']\n",
    "    tokens = nltk.word_tokenize(path)\n",
    "    stems = [stemmer.stem(w) for w in tokens if w not in stopwords]\n",
    "    if not stems:\n",
    "        continue\n",
    "    if label == 'ham':\n",
    "        ham_words.update(stems)\n",
    "    elif label == 'spam':\n",
    "        spam_words.update(stems)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "blacklist = spam_words - ham_words\n",
    "pickle.dump(blacklist, open('blacklist.pkl', 'wb'))\n",
    "\n",
    "print(len(spam_words))\n",
    "print(len(ham_words))\n",
    "print('Blacklist of {} tokens successfully built/loaded'.format(len(blacklist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1101b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set(words.words()) \n",
    "word_set.intersection(blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "for _, row in X_test_bl.iterrows():\n",
    "    path = row['unified']\n",
    "    label = row['Spam/Ham']\n",
    "    tokens = nltk.word_tokenize(path)\n",
    "    stems = [stemmer.stem(w) for w in tokens if w not in stopwords]\n",
    "    if not stems:\n",
    "        continue\n",
    "    stems_set = set(stems)\n",
    "    if stems_set & blacklist: # email's words are in blacklist\n",
    "        if label == 'ham': # ham\n",
    "            fp = fp + 1 \n",
    "        else:\n",
    "            tp = tp + 1\n",
    "    else: # email's words are not in blacklist\n",
    "        if label == 'ham':\n",
    "            tn = tn + 1\n",
    "        else:\n",
    "            fn = fn + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63370a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = [[tn, fp],\n",
    "               [fn, tp]]\n",
    "display(HTML('<table><tr>{}</tr></table>'.format(\n",
    "    '</tr><tr>'.join('<td>{}</td>'.format(\n",
    "        '</td><td>'.join(str(_) for _ in row)) \n",
    "                     for row in conf_matrix))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4f5d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = tn + tp + fn + fp\n",
    "percent_matrix = [[\"{:.1%}\".format(tn/count), \"{:.1%}\".format(fp/count)],\n",
    "                  [\"{:.1%}\".format(fn/count), \"{:.1%}\".format(tp/count)]]\n",
    "display(HTML('<table><tr>{}</tr></table>'.format(\n",
    "    '</tr><tr>'.join('<td>{}</td>'.format(\n",
    "        '</td><td>'.join(str(_) for _ in row)) \n",
    "                     for row in percent_matrix))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b93a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification accuracy: {}\".format(\"{:.1%}\".format((tp+tn)/count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b2d1cb",
   "metadata": {},
   "source": [
    "<h2>LSH</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = enron_df_unified['unified']\n",
    "X_train_lsh = enron_df_unified[:int(len(enron_df_unified)*training_ratio)]\n",
    "X_test_lsh = enron_df_unified[int(len(enron_df_unified)*training_ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8262f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train_lsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d62ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_files = X_train_lsh[X_train_lsh['Spam/Ham'] == 'spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72959c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spam_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada16645",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh = MinHashLSH(threshold=0.5, num_perm=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e745d13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfc028f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
